from abc import ABCMeta, abstractmethod
import dataclasses
import enum
from fractions import Fraction
import itertools
import math
from random import getrandbits as randbits, randint
from random import choices
import statistics
from typing import Any, Callable, Generic, Iterable, Iterator, Literal, NamedTuple, Optional, TypeAlias, TypeVar
import numpy as np
from numpy.random import Generator, default_rng
import scipy.stats

from tqdm import tqdm

from Auxiliary.Getters import chunk
from Auxiliary.ProgressBars import ResourceProgressBar, ResourceUsageProgressBar

## Two main parts:
##      - Selection scheme - Stochastic proportional to fitness,
##          - Needs fitness function, the fitness function is what allows us to bias the selection of individuals to produce the next generation, that are the most fit or best quality.
##      - Recombination and mutation (convergence and diversity measures),
##          - These are what evolve our population, and (hopefully) transition it towards a better fitness population.
## By only choosing the best fit individuals to evolve, and then only choosing the best of those to evolve further, and so on, we will eventually arrive at a population that is close to optimal, or a sub-set of the population is optimal.
## function cluster_groups() -> list[frozenset[Gene]]
## function combined_fitness(groups) -> list[Fraction]
## We can use simulated annealing with this.

## A gene is a strand (a sequence) of bits
Gene: TypeAlias = str

ST = TypeVar("ST")

class GeneBase(NamedTuple):
    """
    Represents a gene base type as a tuple.
    This is the base used for encoding a gene.
    
    Elements
    --------
    `name: str` - The name of the base type.
    
    `format_: str` - The string formatter symbol for
    converting between binary and the base type.
    
    `bits: int` - The number of bits needed to represent one gene.
    """
    name: str
    format_: str
    bits: int

@enum.unique
class Bases(enum.Enum):
    """
    The gene base types a genetic system can use.
    This defines the representation scheme used for chromosomes,
    i.e. is the chromosome a binary sequence of bits
    
    Items
    -----
    `bin = GeneBase("binary", 'b', 1)` - A binary string represenation.
    This uses "base two", i.e. there are only two values a gene can take.
    
    `oct = GeneBase("octal", 'o', 3)` - An octal string representation.
    This uses "base eight", i.e. there are eight possibly values a gene can take.
    
    `hex = GeneBase("hexadecimal", 'h', 4)` - A hexadecimal representation.
    This uses
    """
    bin = GeneBase("binary", 'b', 1)
    oct = GeneBase("octal", 'o', 3)
    hex = GeneBase("hexadecimal", 'x', 4)

class GeneticEncoder(Generic[ST], metaclass=ABCMeta):
    """
    Base class for genetic encoders.
    
    A genetic encoder can encode a solution as a chromosome (a sequence of genes),
    and decode a chromosome into a solution.
    Also defines the genetic fitness evaluation function, which is specific to the encoding.
    
    An individual in the population is a chromosome (a sequence of genes).
    A chromosome represents one possible genotype.
    A genotype is the encoding of one possible candidate solution (which is also called a phenotype).
    Therefore, a population is a set of possible candidate solutions to a problem, encoded in some form that allows the genetic algorithm's genetic operators to operate on them.
    
    This defines the represenation of solutions generated by a genetic system.
    ...need to bear in mind how the genotypes will be evaluated and what the genetic operators will be and how they will work...
    An appropriate fitness evaluator (which is passed the genetic encoder) needs to be able to evaluate an encoding obtained by this encoder.
    """
    
    def __init__(self,
                 gene_length: int = 8,
                 base: Bases | Literal["bin", "oct", "hex"] = "bin") -> None:
        "Create an encoder with a given gene length and base type."
        self.__gene_length: int = gene_length
        self.__base: GeneBase = Bases[base].value
    
    @property
    def gene_length(self) -> int:
        return self.__gene_length
    
    @property
    def base(self) -> GeneBase:
        return self.__base
    
    @abstractmethod
    def encode(self, solution: ST) -> Gene:
        raise NotImplementedError
    
    @abstractmethod
    def decode(self, gene: Gene) -> ST:
        raise NotImplementedError
    
    @abstractmethod
    def evaluate_fitness(self, gene: Gene) -> int | float:
        raise NotImplementedError

class GeneticRecombinator(metaclass=ABCMeta):
    """
    Base class for genetic recombination operators.
    
    A genetic recombinator essentially simply randomly selects
    and swaps genes between two "parent" chromosomes to create new "offspring".
    Swapped bits or bit sub-sequences must always be between those in the same positions in the gene.
    
    A genetic recombinator is agnostic to the representation scheme and encoding used for chromosomes to solutions.
    """
    
    ## We can use a random bit stream to decide when elements to take from the first element, and which from the second: 0 is from first, 1 is from second.
    ## Perhaps we can bit shift, or bitwise or/xor, the two genes together?
    @abstractmethod
    def recombine(self, gene_1: Gene, gene_2: Gene) -> Iterable[Gene]:
        raise NotImplementedError

class TwoPointCrossOver(GeneticRecombinator):
    def recombine(self, gene_1: Gene, gene_2: Gene) -> Iterable[Gene]:
        ## Choose a sub-sequence (in the same place) using two "points", and swap them between the genes.
        left_point, right_point = choices(len(gene_1), k=2)
        return ((gene_1[:left_point] + gene_2[left_point:right_point] + gene_1[right_point:]),
                (gene_2[:left_point] + gene_1[left_point:right_point] + gene_2[right_point:]))

class SplitCrossOver(GeneticRecombinator):
    """
    Splits a pair of chromosomes into two pieces (sub-sequences) in the same place,
    and swaps the pieces between those chromosomes.
    """
    def recombine(self, gene_1: Gene, gene_2: Gene) -> Iterable[Gene]:
        ## Split the genes in half with a sinlge "point" (in the same place), and swap the sub-sequences.
        point: int = randint(0, len(gene_1) - 1)
        return ((gene_1[:point] + gene_2[point:]),
                (gene_2[:point] + gene_1[point:]))

class UniformSwapper(GeneticRecombinator):
    def recombine(self, chorosome_1: Gene, chorosome_2: Gene) -> Iterable[Gene]:
        ## For each bit in the genes, randomly select the bit from the first or the second gene, to build a new one.
        new_chromosome_1: list[str] = []
        new_chromosome_2: list[str] = []
        for gene_1, gene_2 in zip(chorosome_1, chorosome_2):
            if randint(0, 1):
                new_chromosome_1.append(gene_1)
                new_chromosome_2.append(gene_2)
            else:
                new_chromosome_1.append(gene_2)
                new_chromosome_2.append(gene_1)
        return ("".join(new_chromosome_1), "".join(new_chromosome_2))

class GeneticMutator(metaclass=ABCMeta):
    """
    Base class for genetic mutation operators.
    
    For convenience, mutators provide a seperate method for mutating;
        - Any of the standard numeric bases; binary, octal, hexadecimal,
        - Any other arbitrary base over some fixed alphabet.
    
    A mutator is the genetic operator that promotes diversity in a population of possible candidate solutions to a problem.
    A mutator therefore encourages exploration of the search space, by causing the population to spread across a larger area of the search space,
    and evaluate new possible candidate solutions that may be closer to the global optimum than the existing solutions in the population.
    
    It is one of the fundamental operators in causing evolution (i.e. change) in a population,
    and allowing a genetic algorithm to improve the fitness (i.e. quality) of the candidate solutions in that population, towards finding the glocal optimum.
    
    In theory, mutation also helps prevent a genetic algorithm from getting stuck in local optima, by ensuring the population to not become too similar to each other,
    thus slowing convergence to the global optimum, and discouraging exploitation.
    """
    
    @abstractmethod
    def arbitrary_mutate(self, chromosome: list[Any], base: list[Any]) -> list[Any]:
        raise NotImplementedError
    
    @abstractmethod
    def numeric_mutate(self, chromosome: str, base: GeneBase) -> str:
        raise NotImplementedError

class PointMutator(GeneticMutator):
    """
    A simple genetic mutator, which randomly selects one or more genes in a chromosome (with uniform probability),
    and changes their values to a different random value.
    In a binary base representation, this simply flips them to the opposite value.
    """
    
    def __init__(self, points: int) -> None:
        """
        `points: int` - The number of genes in the chromosome to mutate.
        """
        if not isinstance(points, int) or points < 1:
            raise ValueError("Number of points must be an integer greater than zero. "
                             f"Got; {points} of type {type(points)}.")
        self.__points: int = points
    
    def arbitrary_mutate(self, chromosome: list[Any], base: list[Any]) -> list[Any]:
        "Point mutate the given chromosome encoded in an arbitrary base."
        ## Randomly select genes from the arbitrary base set.
        for new_gene, index in zip(choices(base, k=self.__points),
                                   choices(range(len(chromosome)), k=self.__points)):
            ## Insert the new gene into the chromosome at a random position.
            chromosome = chromosome[:index] + new_gene + chromosome[index+1:]
        return chromosome
    
    def numeric_mutate(self, chromosome: str, base: GeneBase) -> str:
        "Point mutate the given chromosome encoded in a numeric base."
        for index in choices(range(len(chromosome)), k=self.__points):
            ## Randomly generate a single digit number in the given base.
            new_gene: str = format(randbits(base.bits), base.format_)
            ## Insert the new gene into the chromosome at a random position.
            chromosome = chromosome[:index] + new_gene + chromosome[index+1:]
        return chromosome

class SwapMutator(GeneticMutator):
    """
    Swap the values of random pairs of genes in the chromosome.
    
    Pick two different genes at random (with uniform probability distribution), and swap their values.
    
    This is common in permutation based encodings, where the set of values need to be preserved, but the order can be changed.
    """
    def arbitrary_mutate(self, chromosome: list[Any], base: list[Any]) -> list[Any]:
        ...
    
    def numeric_mutate(self, chromosome: str, base: GeneBase) -> str:
        ...

class ShuffleMutator(GeneticMutator):
    """
    Pick two different genes at random (with uniform probability), and shuffle (with uniform probability) the sub-sequence of values between them.
    
    A contiguous sub-sequence of genes is randomly selected, and their values are randomly shuffled.
    
    A sub-sequence of a random length (chosen from a given probability density function),
    and a start point of the sub-sequence (chosen with uniform probability).
    """
    def arbitrary_mutate(self, chromosome: list[Any], base: list[Any]) -> list[Any]:
        ...
    
    def numeric_mutate(self, chromosome: str, base: GeneBase) -> str:
        ...

class InversionMutator(GeneticMutator):
    """
    Pick two different genes at random (with uniform probability distribution), and invert the sub-sequence of values between them.
    
    Similar to shuffle, except invert (flip, or pivot around its center) the sub-sequence instead of performing the expensive shuffle operation.
    This still disrupts the order, but mostly preserves adjacency of gene values (within the sub-sequence only).
    """
    def arbitrary_mutate(self, chromosome: list[Any], base: list[Any]) -> list[Any]:
        ...
    
    def numeric_mutate(self, chromosome: str, base: GeneBase) -> str:
        ...



class Selector:
    pass

class ProportionateSelector(Selector):
    pass

class RankedSelector(Selector):
    pass

class TournamentSelector(Selector):
    pass



@dataclasses.dataclass(frozen=True)
class GeneticAlgorithmSolution:
    best_individual: Gene
    best_fitness: Fraction
    population: list[Gene] ## TODO Order the population such that the highest fitness individuals occur first.
    fitness_values: list[Fraction]
    max_fitness_reached: bool = False
    max_generations_reached: bool = False
    stagnation_limit_reached: bool = False

class GeneticSystem:
    """
    
    Genetic Operator
    ----------------
    
    1. Solution Encoder - Representation as chromosomes formed by a sequence of genes.
    
        A solution is called the phenotype,
        and its encoding that the genetic algorithm operates on and evolves is called the genotype.
        
        The decoder function is required, the encoder is optional.
        
        In order to evaluate fitness and to return a best-fit solution at the end,
        the algorithm needs to be able to decode genotypes to phenotypes.
        
        When initialising a problem, one may want to specific an initial set of solutions to evolve,
        to do this the algorithm needs to be able to encode phenotypes to genotypes.
        
        - Numeric representation; binary, octal, or hexadecimal sequence;
            - In binary, the nucleotide bases are; 1 or 2, for example.
            - For some problems, it is difficult to encode a solution in binary,
              you may need to split the chromosome up into mutliple sub-sequences
              to encode different properties of the solution. The quality of the complete
              solution is then the sum of the quality of its parts.
        
        - Identifier list representation - Any sized set of arbitrary identifiers for properties or elements of a solution;
            - The nucleotide bases are any of a set of identifiers; "london", "birmingham", "leeds".
            - Useful when solution length is known, but ordering needs to be optimised.
    
    2. Selection Scheme and Fitness Function
    
        - Deterministic Selection: Only best n < pop_size reproduce, in this case the fitness function is not necessary.
        - Proportional Seletion: Reproduction chances are proportional to fitness value.
        - Ranked Fitness Selection: Solutions are ranked according to fitness, reproduction chance proportional to fitness.
        - Tournament Selection: Solutions compete against each other, fittest wins and gets to reproduce.
        
        - Elitism in selection:
        - Convergence and diversity biases in selection: Affect selection pressure towards high values of fitness, and thus exploration/exploitation trade-off.
        - Boltzmann decay for biases:
            ...In Boltzmann selection, a continuously varying temperature controls the rate of selection according to a preset schedule. The temperature starts out high, which means that the selection pressure is low. The temperature is gradually lowered, which gradually increases the selection pressure, thereby allowing the GA to narrow in more closely to the best part of the search space while maintaining the appropriate degree of diversity...
    
    3. Genetic Recombinator
    
    
    
    4. Genetic Mutator
    
    
    
    Algorithm procedure/structure
    -----------------------------
    
    1. population initialisation
    
    2. population evaluation
    
    3. stopping condition -> best solution
    
    4. selection
    
    5. crossover
    
    6. mutation
    
    7. population evaluation and update 3
    
    """
    
    __slots__ = (## Functions defining the system's genetic operators.
                 "__genetic_encoder",
                 "__genetic_recombinator",
                 "__genetic_mutator",
                 "__random_generator")
    
    def __init__(self,
                 encoder: GeneticEncoder,
                 recombinator: GeneticRecombinator,
                 mutator: GeneticMutator
                 ) -> None:
        
        self.__genetic_encoder: GeneticEncoder = encoder
        self.__genetic_recombinator: GeneticRecombinator = recombinator
        self.__genetic_mutator: GeneticMutator = mutator
        
        self.__random_generator: Generator = default_rng()
    
    @staticmethod
    def linear_decay(diversity_bias: Fraction, decay: Fraction) -> Fraction:
        "Decay according to: `max(0.0, initial_diversity_bias - ((1.0 - bias_decay) * generation))`."
        return max(0.0, diversity_bias - decay)
    
    @staticmethod
    def polynomial_decay(diversity_bias: Fraction, decay: Fraction) -> Fraction:
        "Decay according to: `initial_diversity_bias ^ (generation / (1.0 - bias_decay))`."
        return diversity_bias ** (1.0 / (1.0 - decay))
    
    @staticmethod
    def exponential_decay(diversity_bias: Fraction, decay: Fraction) -> Fraction:
        "Decay according to: `initial_diversity_bias * ((1.0 - bias_decay) ^ generation)`."
        return diversity_bias * (1.0 - decay)
    
    @staticmethod
    def get_decay_function(decay_type: "DecayType" | Literal["lin", "pol", "exp"]) -> Callable[[Fraction, Fraction], Fraction]:
        if isinstance(decay_type, DecayType):
            return decay_type.value[0]
        return DecayType[decay_type].value[0]
    
    def set_operators(self) -> None:
        ...
    
    def initialise(self) -> None:
        ...
    
    def run(self,
            
            init_pop_size: int,
            max_pop_size: int,
            expansion_factor: Fraction,
            
            # scaling_scheme: Literal["lin", "sigma", "power-law", "boltzmann"],
            selection_scheme: Literal["prop", "rank"], ## "trans-ranked", "tournament", "SUS" : Params for tournament >> tournament_size: int, inner_selection: best | prop | rank | trans-ranked | SUS
            
            ## use_ranked_fitness: bool = False,
            ## best_fit_gets_proportion_of_pie: Fraction = 1,
            ## P_c must be greater than 1/2 (50%) to actually bias it towards better individuals, otherwise if P_c < 0.5 last individual would actually have more chance to to be picked than second to last.
            ## But selection should be proportional to ratio of biases = (convergence_bias / diversity_bias)
            
            survival_factor: Fraction, 
            # survival_factor_rate: Optional[Fraction],
            # survival_factor_rate_type: Optional["DecayType" | Literal["lin", "pol", "exp"]],
            survival_elitism_factor: Optional[Fraction], ## Fraction of the surviving that are the elite.
            # survival_elitism_growth: Optional[Fraction],
            # survival_elitism_growth_type: Optional["DecayType" | Literal["lin", "pol", "exp"]],
            ## survival_filter: Optional[Callable[[Chromosome, Fraction, dict[str, Fraction], Fraction], bool]] = None,
            ##      - Function: (individual, fitness, fitness_statisitcs: statistic_name -> statistic, fitness_threshold) -> survived
            ## Common filters are to choose those x% above the mean or median, or to choose only those within x% of the fitness threshold.
            
            replacement: bool,
            reproduction_elitism_factor: Fraction,
            reproduction_elitism_growth: Fraction,
            reproduction_elitism_growth_type: Optional["DecayType" | Literal["lin", "pol", "exp"]],
            
            mutation_factor: Fraction,
            mutation_factor_growth: Fraction,
            mutation_factor_growth_type: Optional["DecayType" | Literal["lin", "pol", "exp"]],
            mutation_distribution: Literal["uniform", "half_logistic", "trunc_exponential"],
            mutation_step_size: Fraction,
            mutation_step_size_decay: Fraction,
            mutation_step_size_decay_type: Optional["DecayType" | Literal["lin", "pol", "exp"]],
            
            max_generations: Optional[int],
            fitness_threshold: Optional[Fraction],
            fitness_proportion: Optional[Fraction | int],
            stagnation_limit: Optional[int | Fraction],
            stagnation_proportion: Optional[Fraction | int] = 0.10, ## TODO Could use numpy.allclose
            
            ## These are used only for proportional fitness
            diversity_bias: Optional[Fraction] = Fraction(0.95),
            diversity_bias_decay: Optional[int | Fraction] = 100,
            diversity_bias_decay_type: "DecayType" | Literal["lin", "pol", "exp", "hl-exp"] = "exp" # ["threshold-converge", "stagnation-diverge"]
            
            ) -> GeneticAlgorithmSolution:
        
        """
        
        Parameters
        ----------
        
        `survival_factor: Fraction` - Survival factor defines how much culling (equal to 1.0 - survival factor) we have, i.e. how much of the population for a given generation does not survive to the reproduction stage, and are not even considered for selection for recombination/reproduction.
        Low survival factor encourages exploitation of better solutions and speeds up convergence, by culling all but the best individuals, and allowing only the best to reproduce and search (relatively) locally to those best.
        
        `survival_factor_rate: Fraction` - 
        
        `survival_factor_change: Literal["decrease", "increase"]` - Usually, if replacement is enabled, it is desirable to start with a high survive factor to promote early exploration of the search space and decrease the factor to promote greater exploitation
        as the search progresses, focusing search towards the very best solutions it has found.
        
        `replacement: bool = True` - Defines whether parents are replaced by their offspring, or the parents survive to the next generation along with their offspring.
        If they are allowed to survive then a survival factor of 1.0 would mean recombination/reproduction would stop happening after reaching the maximum population size.
        If replacement is allowed, then the problem may be that our solutions might actually get worse if our exploration did not go well.
        If the survival factor is high, then reproducing without replacement is a problem, since we get much more limited to how much we can explore the search space and the population approaches its max size,
        so a high survival factor later in the search (when all the solutions are very similar) may discourage exploration (similar to how we want to use creep mutation later in the search to deal with the last little bit of optimisation to reach the exact global optimum).
        
        `stagnation_proportion: Fraction` - If given and not none, return if the average fitness of the best fitting fraction of the population is stagnated (does not increase) for a number of generations equal to the stagnation limit.
        This intuition is that the search should stop only if a "large" proportion of the best quality candidates are not making significant improvement for a "long" time.
        Otherwise, return of the fitness of the best fitting individual is stagenated for the stagnation limit.
        If only the best fitting individual is used as the test of stagnation, it may result in a premature return of the algorithm, when other high fitness individuals would have achieved better fitness that the current maximum if allowed to evolve more
        particularly by creep mutation, which can we time consuming.
        
        `mutation_step_size: Fraction` - The degree of mutation or "step size" (i.e. the amount a single gene can change), change between totally random mutation and creep mutation based on generations or fitness to threshold.
        
        `max_generations: Optional[int]` -
        
        `fitness_threshold: Optional[Fraction]` -
        
        `fitness_proportion: Optional[Fraction | int]` - Return if the average fitness of the best fitness fraction of the population is above the fitness threshold.
        
        `stagnation_limit: Optional[int | Fraction]` - The maximum number of stagnated generations before returning.
        
        `stagnation_proportion: Optional[Fraction | int] = 0.10` -
        
        Stop Conditions
        ---------------
        
        The algorithm runs until one of the following stop conditions has been reached:
        
            - A solution is found that reaches or exceeds the fitness threshold,
            - The maximum generation limit has been reached,
            - The maximum running time or memory usage has been reached,
            - The best fit solutions have stagnated (reached some maxima) such that more generations are not increasing fitness,
              the algorithm may have found the global maxima, or it may be stuck in a logcal maxima.
        
        Notes
        -----
        
        To perform steady state selection for reproduction set;
            - survival_factor = 1.0 - X, where X is fraction of individuals to be culled,
            - survival_elitism_factor = 1.0, such that only the best survive (and the worst are culled) deterministically,
            - disable replacement.
        """
        
        ## TODO Add tqdm, logging, data collection (with pandas?), and data visualisation.
        
        if survival_factor >= Fraction(1.0):
            raise ValueError("Survival factor must be less than 1.0."
                             f"Got; {survival_factor=}.")
        
        if replacement and (expansion_factor * survival_factor) <= 1.0:
            raise ValueError("Population size would shrink or not grow "
                             f"with; {expansion_factor=}, {survival_factor=}."
                             "Their multiple must be greater than 1.0.")
        
        if stagnation_limit is not None and not isinstance(stagnation_limit, int):
            if max_generations is None:
                raise TypeError("Stagnation limit must be an integer if the maximum generations is not given or None."
                                f"Got; {stagnation_limit=} of type {type(stagnation_limit)} and {max_generations=} of {type(max_generations)}.")
            stagnation_limit = int(stagnation_limit * max_generations)
        
        population: list[Gene] = self._create_population(init_pop_size)
        fitness_values: list[Fraction] = [self.__genetic_encoder.evaluate_fitness(individual)
                                          for individual in population]
        
        ## If elitism is enabled for either selection or mutation then the population and their fitness values need to be ordered.
        if survival_elitism_factor is not None:
            population, fitness_values = zip(*sorted(zip(population, fitness_values),
                                                        key=lambda item: item[1]))
            population = list(population)
            fitness_values = list(fitness_values)
        
        max_fitness, min_fitness = max(fitness_values), min(fitness_values)
        generation: int = 0
        
        ## Variables for checking stagnation
        best_fitness_achieved: Fraction = max_fitness
        stagnated_generations: int = 0
        
        if diversity_bias_decay_type is not None:
            diversity_bias_decay_function = self.get_decay_function(diversity_bias_decay_type)
        if mutation_factor_growth_type is not None:
            mutation_factor_growth_function = self.get_decay_function(mutation_factor_growth_type)
        
        progress_bar = ResourceProgressBar(initial=1, total=max_generations)
        
        while not (generation >= max_generations):
            if diversity_bias is not None:
                ## Update the convergence and diversity biases;
                ##      - Convergence increases by the decay factor,
                ##      - Diversity reduces by the decay factor.
                if diversity_bias_decay is not None and diversity_bias_decay_type is not None:
                    diversity_bias = diversity_bias_decay_function(diversity_bias, diversity_bias_decay)
                
                ## Apply biases to the fitness values;
                ##      - Diversity bias increases low fitness, encouraging exploration,
                ##        Individuals gain fitness directly proportional to diversity bias and how much worse than the maximum fitness.
                fitness_values = [fitness
                                  + ((max_fitness - fitness) * diversity_bias)
                                  for fitness in fitness_values]
            
            base_population_size: int = len(population)
            
            ## Select part of the existing population to survive to the next generation and cull the rest;
            ##      - The selection scheme is random (unless the elitism factor is 1.0) with chance of survival proportional to fitness.
            ##      - This step emulates Darwin's principle of survival of the fittest.
            population, fitness_values = self._select_population(population, fitness_values, survival_factor, survival_elitism_factor)
            
            ## Recombine the survivors to produce offsrping and expand the population to the lower of;
            ##      - The max population size,
            ##      - increase the size by our maximum expansion factor.
            desired_population_size: int = min(math.ceil(base_population_size * expansion_factor), max_pop_size)
            population = self._grow_population(population, fitness_values, desired_population_size, replacement)
            
            ## Randomly mutate the grown population
            if generation != 0:
                mutation_factor = mutation_factor_growth_function(mutation_factor, mutation_factor_growth)
            mutated_population: list[Gene] = self._mutate_population(population, fitness_values, mutation_distribution)
            
            ## Update the population and fitness values with the new generation.
            population = mutated_population
            fitness_values: list[Fraction] = [self.__genetic_encoder.evaluate_fitness(individual)
                                              for individual in population]
            
            ## If elitism is enabled the population and their fitness values need to be ordered.
            if survival_elitism_factor is not None:
                population, fitness_values = zip(*sorted(zip(population, fitness_values),
                                                         key=lambda item: item[1]))
                population = list(population)
                fitness_values = list(fitness_values)
                max_individual = population[-1]
                max_fitness = fitness_values[-1]
            else:
                max_fitness_index, max_fitness = max(enumerate(fitness_values), key=lambda item: item[1])
                max_individual = population[max_fitness_index]
                min_fitness = min(fitness_values)
            
            if max_fitness > best_fitness_achieved:
                best_fitness_achieved = max_fitness
                best_individual_achieved = max_individual
            else: stagnated_generations += 1
            
            generation += 1
            progress_bar.update(data={"Best fitness" : str(best_fitness_achieved)})
            
            ## Determine whether the fitness threshold has been reached.
            if best_fitness_achieved >= fitness_threshold:
                return GeneticAlgorithmSolution(best_individual_achieved, best_fitness_achieved, population, fitness_values, max_fitness_reached=True)
            
            ## Determine whether the stagnation limit has been reached.
            if stagnated_generations == stagnation_limit:
                return GeneticAlgorithmSolution(best_individual_achieved, best_fitness_achieved, population, fitness_values, stagnation_limit_reached=True)
        
        return GeneticAlgorithmSolution(best_individual_achieved, best_fitness_achieved, population, fitness_values, max_generations_reached=True)
    
    def _create_population(self, population_size: int) -> list[Gene]:
        "Create a list of gene strings, representing a population of the given size."
        total_bits: int = self.__genetic_encoder.base.bits * self.__genetic_encoder.gene_length
        ## Could we just represent these as integers? The bits are the same anyway
        return [format(randbits(total_bits),
                       self.__genetic_encoder.base.format_).zfill(self.__genetic_encoder.gene_length)
                for _ in range(population_size)]
    
    def _select_population(self,
                           population: list[Gene],
                           fitness_values: list[Fraction],
                           survival_factor: Fraction,
                           elitism_factor: Optional[Fraction]
                           ) -> tuple[list[Gene], list[Fraction]]:
        """
        Select individuals from the current population to survive to and reproduce for the next generation.
        Individuals that do not survive are said to be culled from the population and do not get a chance to reproduce and propagate features of their genes to the next generation.
        
        The intuition is that individuals with sufficiently low fitness (relativeo the other individuals in the population) will get out competed by better adapted individuals and therefore will not survive to reproduce offspring.
        The assumption, is that such individuals don't have genes with desirable features, and therefore we don't want them in the gene pool at all.
        
        Reproduction with replacement might be considered similar to population culling and reproduction without replacement,
        however this is not true, since the prior allows low-fitness individuals to dilute the mating pool and allows potentially undesirable genes to remain in gene pool.
        
        A low survival factor results in a more exploitative search and faster convergence,
        since a large proportion of the population is culled, and the search is much more focused on a small set of genes/area of the search space.
        This is particuarly true if the elitism factor is high, because lower fitness indivuduals will have much less chance to reproduce and contribute their genes to future generations,
        and higher fitness individuals will dominate the mating proceedure.
        
        The survival factor decay exists to allow a greater number of individuals to survive to reproduce at earlier generations to promote early exploration,
        but increasingly reducing the number of individuals that survive to increasingly focus the search and exploit the best quality solutions.
        
        Parameters
        ----------
        
        `population: list` -
        
        `fitness_values: list[Fraction]` - 
        If `elitism_factor` is not None, then the fitness values must be sorder in ascending order.
        
        `survival_factor: Fraction` -
        
        `elitism_factor: {Fraction | None}` - 
        """
        
        ## The current population size and the quantity of them to choose to survive to the next generation.
        population_size: int = len(population)
        survive_quantity: int = math.ceil(population_size * survival_factor)
        
        ## If all individuals in the current population survive to reproduce then skip the culling phase.
        if  population_size == survive_quantity:
            return (population, fitness_values)
        
        ## If elitism factor is not given or None then always choose randomly with probability proportion.
        if elitism_factor is None:
            return zip(*choices(zip(population, fitness_values),
                                fitness_values,
                                k=survive_quantity))
        
        ## The quantity of elite individuals that are guaranteed to survive.
        elite_quantity = math.ceil(survive_quantity * elitism_factor)
        
        ## If all surviving are elite, then skip random selection phase,
        ## simply select deterministically the best individuals from the previous generation.
        if survive_quantity == elite_quantity:
            return (population[population_size - survive_quantity:],
                    fitness_values[population_size - survive_quantity:])
        
        ## Non-elite part of the population chosen from randomly to generate competing quantity of survive quantity
        competing_quantity: int = survive_quantity - elite_quantity
        _popluation: list[Gene] = population[0:population_size - elite_quantity]
        _fitness_values: list[Fraction] = fitness_values[0:population_size - elite_quantity]
        
        _popluation, _fitness_values = map(list, zip(*choices(list(zip(_popluation, _fitness_values)), ## TODO getitem_zip(*iterables: SupportsLenAndGetItem)
                                                              _fitness_values,
                                                              k=competing_quantity)))
        
        return (_popluation + population[population_size - elite_quantity:],
                _fitness_values + fitness_values[population_size - elite_quantity:])
    
    def _grow_population(self,
                         population: list[Gene],
                         fitness_values: Optional[list[Fraction]],
                         desired_population_size: int,
                         replace: bool
                         ) -> list[Gene]:
        """
        Grow the population to the desired size.
        """
        offspring_quantity: int = desired_population_size
        if not replace:
            offspring_quantity -= len(population)
        if offspring_quantity == 0:
            return population
        
        ## This should zip population and fitness together, or should use indices to make it compatible with ranked.
        # self.__random_generator
        
        offspring: list[Gene] = []
        total_parents: int = (offspring_quantity + (offspring_quantity % 2))
        parent_pairs: Iterator[tuple[Gene, Gene]] = chunk(choices(population,
                                                                  fitness_values,
                                                                  k=total_parents),
                                                          size=2,
                                                          quantity=total_parents // 2,
                                                          as_type=tuple)
        
        for parent_1, parent_2 in parent_pairs:
            children: list[Gene] = self.__genetic_recombinator.recombine(parent_1, parent_2)
            max_children: int = min(len(children), offspring_quantity - len(offspring))
            offspring.extend(children[:max_children])
        
        return offspring if replace else population + offspring
    
    def _mutate_population(self,
                           population: list[Gene],
                           mutation_factor: Fraction,
                           mutation_distribution: Literal["uniform", "half_logistic", "trunc_exponential"]
                           ) -> list[Gene]:
        """
        Mutation the population randomly.
        """
        
        mutations_quantity: int = math.floor(len(population) * mutation_factor)
        mutated_population: list[Gene] = population
        
        if mutation_distribution == "uniform":
            indices = self.__random_generator.choice(len(population), mutations_quantity)
        elif mutation_distribution == "half_logistic":
            indices = scipy.stats.genhalflogistic.rvs(1, scale=len(population), size=mutations_quantity).astype(int)
        elif mutation_distribution == "trunc_exponential":
            indices = (len(population) - 1) - scipy.stats.truncexpon.rvs(1, scale=len(population), size=mutations_quantity).astype(int)
        
        for index in indices:
            mutated_population[index] = mutate(mutated_population[index],
                                               self.__genetic_encoder.base)
        
        return mutated_population

@enum.unique
class DecayType(enum.Enum):
    lin = (GeneticSystem.linear_decay,)
    pol = (GeneticSystem.polynomial_decay,)
    exp = (GeneticSystem.exponential_decay,)